{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:01.083219Z",
     "iopub.status.busy": "2020-08-12T21:06:01.082930Z",
     "iopub.status.idle": "2020-08-12T21:06:02.012154Z",
     "shell.execute_reply": "2020-08-12T21:06:02.011268Z",
     "shell.execute_reply.started": "2020-08-12T21:06:01.083188Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.013642Z",
     "iopub.status.busy": "2020-08-12T21:06:02.013430Z",
     "iopub.status.idle": "2020-08-12T21:06:02.020378Z",
     "shell.execute_reply": "2020-08-12T21:06:02.019320Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.013617Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.022351Z",
     "iopub.status.busy": "2020-08-12T21:06:02.021940Z",
     "iopub.status.idle": "2020-08-12T21:06:02.029342Z",
     "shell.execute_reply": "2020-08-12T21:06:02.028771Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.022315Z"
    }
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                            transforms.Grayscale(num_output_channels=1),\n",
    "                            transforms.Resize(10),\n",
    "                            transforms.ToTensor()\n",
    "                                      ])\n",
    "train_data = datasets.ImageFolder(root = 'dga_im',transform=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.030872Z",
     "iopub.status.busy": "2020-08-12T21:06:02.030526Z",
     "iopub.status.idle": "2020-08-12T21:06:02.034424Z",
     "shell.execute_reply": "2020-08-12T21:06:02.033714Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.030836Z"
    }
   },
   "outputs": [],
   "source": [
    "train_iterator = data.DataLoader(train_data, \n",
    "                                 shuffle = True, \n",
    "                                 batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.035570Z",
     "iopub.status.busy": "2020-08-12T21:06:02.035386Z",
     "iopub.status.idle": "2020-08-12T21:06:02.306939Z",
     "shell.execute_reply": "2020-08-12T21:06:02.306332Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.035547Z"
    }
   },
   "outputs": [],
   "source": [
    "mean = 0.0\n",
    "for images, _ in train_iterator:\n",
    "    batch_samples = images.size(0) \n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    mean += images.mean(2).sum(0)\n",
    "mean = mean / len(train_iterator.dataset)\n",
    "\n",
    "var = 0.0\n",
    "for images, _ in train_iterator:\n",
    "    batch_samples = images.size(0)\n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    var += ((images - mean.unsqueeze(1))**2).sum([0,2])\n",
    "std = torch.sqrt(var / (len(train_iterator.dataset)*10*10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.308310Z",
     "iopub.status.busy": "2020-08-12T21:06:02.307959Z",
     "iopub.status.idle": "2020-08-12T21:06:02.314112Z",
     "shell.execute_reply": "2020-08-12T21:06:02.313226Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.308277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1446])\n",
      "tensor([0.1971])\n"
     ]
    }
   ],
   "source": [
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.315330Z",
     "iopub.status.busy": "2020-08-12T21:06:02.315074Z",
     "iopub.status.idle": "2020-08-12T21:06:02.327847Z",
     "shell.execute_reply": "2020-08-12T21:06:02.326853Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.315303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507\n",
      "28\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                            transforms.Grayscale(num_output_channels=1),\n",
    "                            transforms.Resize(10),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean = [mean], std = [std])\n",
    "                                      ])\n",
    "train_data = datasets.ImageFolder(root = 'dga_im',transform=train_transforms)\n",
    "RATIO = 0.9\n",
    "n_train_examples = int(len(train_data) * RATIO)\n",
    "n_orginalvalid_examples = len(train_data) - n_train_examples\n",
    "n_valid_examples = int((n_orginalvalid_examples)*0.5)\n",
    "n_test_examples = n_orginalvalid_examples - n_valid_examples\n",
    "print(n_train_examples)\n",
    "print(n_valid_examples)\n",
    "print(n_test_examples)\n",
    "\n",
    "train_data, valid_data, test_data = data.random_split(train_data, \n",
    "                                           [n_train_examples, n_valid_examples, n_test_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.329464Z",
     "iopub.status.busy": "2020-08-12T21:06:02.329164Z",
     "iopub.status.idle": "2020-08-12T21:06:02.333726Z",
     "shell.execute_reply": "2020-08-12T21:06:02.332994Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.329427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 507\n",
      "Number of validation examples: 28\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.336644Z",
     "iopub.status.busy": "2020-08-12T21:06:02.336420Z",
     "iopub.status.idle": "2020-08-12T21:06:02.340957Z",
     "shell.execute_reply": "2020-08-12T21:06:02.340172Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.336618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 507\n",
      "Number of validation examples: 28\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.342947Z",
     "iopub.status.busy": "2020-08-12T21:06:02.342744Z",
     "iopub.status.idle": "2020-08-12T21:06:02.353476Z",
     "shell.execute_reply": "2020-08-12T21:06:02.352631Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.342922Z"
    }
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, \n",
    "                               out_channels = 3, \n",
    "                               kernel_size = 3)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = 3, \n",
    "                               out_channels = 6, \n",
    "                               kernel_size = 3)\n",
    "        \n",
    "        self.fc_1 = nn.Linear(216, 72)\n",
    "        self.fc_2 = nn.Linear(72, 24)\n",
    "        self.fc_3 = nn.Linear(24, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        \n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        h = x\n",
    "        \n",
    "        x = self.fc_1(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc_2(x)\n",
    "        \n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc_3(x)\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "        return x, h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.354869Z",
     "iopub.status.busy": "2020-08-12T21:06:02.354663Z",
     "iopub.status.idle": "2020-08-12T21:06:02.360208Z",
     "shell.execute_reply": "2020-08-12T21:06:02.359217Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.354845Z"
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 6\n",
    "\n",
    "model = LeNet(OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.361756Z",
     "iopub.status.busy": "2020-08-12T21:06:02.361517Z",
     "iopub.status.idle": "2020-08-12T21:06:02.367630Z",
     "shell.execute_reply": "2020-08-12T21:06:02.366624Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.361730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 17,724 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.369455Z",
     "iopub.status.busy": "2020-08-12T21:06:02.369133Z",
     "iopub.status.idle": "2020-08-12T21:06:02.374538Z",
     "shell.execute_reply": "2020-08-12T21:06:02.373627Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.369417Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.375972Z",
     "iopub.status.busy": "2020-08-12T21:06:02.375757Z",
     "iopub.status.idle": "2020-08-12T21:06:02.380839Z",
     "shell.execute_reply": "2020-08-12T21:06:02.379994Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.375947Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=8\n",
    "train_iterator = data.DataLoader(train_data, \n",
    "                                 shuffle = True, \n",
    "                                 batch_size = BATCH_SIZE)\n",
    "\n",
    "valid_iterator = data.DataLoader(valid_data, \n",
    "                                 batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.382135Z",
     "iopub.status.busy": "2020-08-12T21:06:02.381932Z",
     "iopub.status.idle": "2020-08-12T21:06:02.385848Z",
     "shell.execute_reply": "2020-08-12T21:06:02.384948Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.382111Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.387943Z",
     "iopub.status.busy": "2020-08-12T21:06:02.387470Z",
     "iopub.status.idle": "2020-08-12T21:06:02.392434Z",
     "shell.execute_reply": "2020-08-12T21:06:02.391395Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.387904Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.393996Z",
     "iopub.status.busy": "2020-08-12T21:06:02.393693Z",
     "iopub.status.idle": "2020-08-12T21:06:02.397831Z",
     "shell.execute_reply": "2020-08-12T21:06:02.397139Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.393958Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.399269Z",
     "iopub.status.busy": "2020-08-12T21:06:02.398893Z",
     "iopub.status.idle": "2020-08-12T21:06:02.405629Z",
     "shell.execute_reply": "2020-08-12T21:06:02.404920Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.399241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.406913Z",
     "iopub.status.busy": "2020-08-12T21:06:02.406705Z",
     "iopub.status.idle": "2020-08-12T21:06:02.411516Z",
     "shell.execute_reply": "2020-08-12T21:06:02.410489Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.406888Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.412720Z",
     "iopub.status.busy": "2020-08-12T21:06:02.412504Z",
     "iopub.status.idle": "2020-08-12T21:06:02.418753Z",
     "shell.execute_reply": "2020-08-12T21:06:02.417849Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.412694Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.420038Z",
     "iopub.status.busy": "2020-08-12T21:06:02.419832Z",
     "iopub.status.idle": "2020-08-12T21:06:02.432659Z",
     "shell.execute_reply": "2020-08-12T21:06:02.431782Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.420013Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(model, iterator, optimizer, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for (x, y) in iterator:\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        y_pred, _ = model(x)\n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.433866Z",
     "iopub.status.busy": "2020-08-12T21:06:02.433664Z",
     "iopub.status.idle": "2020-08-12T21:06:02.438491Z",
     "shell.execute_reply": "2020-08-12T21:06:02.437681Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.433841Z"
    }
   },
   "outputs": [],
   "source": [
    "val_acc=[]\n",
    "train_acc=[]\n",
    "\n",
    "train_loss=[]\n",
    "val_loss=[]\n",
    "epoch_x_axis=[i for i in range(0,100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:02.439819Z",
     "iopub.status.busy": "2020-08-12T21:06:02.439623Z",
     "iopub.status.idle": "2020-08-12T21:06:56.744701Z",
     "shell.execute_reply": "2020-08-12T21:06:56.744116Z",
     "shell.execute_reply.started": "2020-08-12T21:06:02.439795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.738 | Train Acc: 24.74%\n",
      "\t Val. Loss: 1.654 |  Val. Acc: 25.00%\n",
      "Epoch: 02 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.382 | Train Acc: 44.21%\n",
      "\t Val. Loss: 1.289 |  Val. Acc: 46.88%\n",
      "Epoch: 03 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.181 | Train Acc: 52.93%\n",
      "\t Val. Loss: 1.115 |  Val. Acc: 50.00%\n",
      "Epoch: 04 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.100 | Train Acc: 56.18%\n",
      "\t Val. Loss: 1.031 |  Val. Acc: 50.00%\n",
      "Epoch: 05 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.030 | Train Acc: 60.35%\n",
      "\t Val. Loss: 0.958 |  Val. Acc: 56.25%\n",
      "Epoch: 06 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.051 | Train Acc: 59.11%\n",
      "\t Val. Loss: 0.943 |  Val. Acc: 50.00%\n",
      "Epoch: 07 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.991 | Train Acc: 61.07%\n",
      "\t Val. Loss: 0.985 |  Val. Acc: 43.75%\n",
      "Epoch: 08 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.979 | Train Acc: 61.59%\n",
      "\t Val. Loss: 0.889 |  Val. Acc: 59.38%\n",
      "Epoch: 09 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.982 | Train Acc: 62.17%\n",
      "\t Val. Loss: 0.946 |  Val. Acc: 56.25%\n",
      "Epoch: 10 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.964 | Train Acc: 62.83%\n",
      "\t Val. Loss: 0.913 |  Val. Acc: 62.50%\n",
      "Epoch: 11 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.961 | Train Acc: 62.96%\n",
      "\t Val. Loss: 0.876 |  Val. Acc: 59.38%\n",
      "Epoch: 12 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.970 | Train Acc: 61.13%\n",
      "\t Val. Loss: 0.913 |  Val. Acc: 53.12%\n",
      "Epoch: 13 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.949 | Train Acc: 64.06%\n",
      "\t Val. Loss: 0.890 |  Val. Acc: 65.62%\n",
      "Epoch: 14 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.943 | Train Acc: 61.91%\n",
      "\t Val. Loss: 0.949 |  Val. Acc: 53.12%\n",
      "Epoch: 15 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.948 | Train Acc: 63.28%\n",
      "\t Val. Loss: 0.884 |  Val. Acc: 56.25%\n",
      "Epoch: 16 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.918 | Train Acc: 64.13%\n",
      "\t Val. Loss: 0.847 |  Val. Acc: 65.62%\n",
      "Epoch: 17 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.906 | Train Acc: 64.84%\n",
      "\t Val. Loss: 0.876 |  Val. Acc: 71.88%\n",
      "Epoch: 18 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.914 | Train Acc: 64.97%\n",
      "\t Val. Loss: 0.826 |  Val. Acc: 65.62%\n",
      "Epoch: 19 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.889 | Train Acc: 65.49%\n",
      "\t Val. Loss: 0.829 |  Val. Acc: 71.88%\n",
      "Epoch: 20 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.892 | Train Acc: 64.65%\n",
      "\t Val. Loss: 0.840 |  Val. Acc: 62.50%\n",
      "Epoch: 21 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.875 | Train Acc: 65.04%\n",
      "\t Val. Loss: 0.877 |  Val. Acc: 53.12%\n",
      "Epoch: 22 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.862 | Train Acc: 66.02%\n",
      "\t Val. Loss: 0.879 |  Val. Acc: 56.25%\n",
      "Epoch: 23 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.884 | Train Acc: 66.08%\n",
      "\t Val. Loss: 0.861 |  Val. Acc: 62.50%\n",
      "Epoch: 24 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.883 | Train Acc: 64.71%\n",
      "\t Val. Loss: 0.845 |  Val. Acc: 65.62%\n",
      "Epoch: 25 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.866 | Train Acc: 63.61%\n",
      "\t Val. Loss: 0.762 |  Val. Acc: 68.75%\n",
      "Epoch: 26 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.843 | Train Acc: 65.89%\n",
      "\t Val. Loss: 0.808 |  Val. Acc: 68.75%\n",
      "Epoch: 27 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.842 | Train Acc: 66.08%\n",
      "\t Val. Loss: 0.870 |  Val. Acc: 59.38%\n",
      "Epoch: 28 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.839 | Train Acc: 67.06%\n",
      "\t Val. Loss: 0.784 |  Val. Acc: 65.62%\n",
      "Epoch: 29 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.829 | Train Acc: 68.16%\n",
      "\t Val. Loss: 0.907 |  Val. Acc: 53.12%\n",
      "Epoch: 30 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.819 | Train Acc: 66.28%\n",
      "\t Val. Loss: 0.841 |  Val. Acc: 68.75%\n",
      "Epoch: 31 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.821 | Train Acc: 67.06%\n",
      "\t Val. Loss: 0.758 |  Val. Acc: 78.12%\n",
      "Epoch: 32 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.795 | Train Acc: 69.53%\n",
      "\t Val. Loss: 0.787 |  Val. Acc: 65.62%\n",
      "Epoch: 33 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.791 | Train Acc: 71.09%\n",
      "\t Val. Loss: 0.772 |  Val. Acc: 68.75%\n",
      "Epoch: 34 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.798 | Train Acc: 68.29%\n",
      "\t Val. Loss: 0.780 |  Val. Acc: 71.88%\n",
      "Epoch: 35 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.788 | Train Acc: 69.27%\n",
      "\t Val. Loss: 0.708 |  Val. Acc: 75.00%\n",
      "Epoch: 36 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.787 | Train Acc: 69.79%\n",
      "\t Val. Loss: 0.728 |  Val. Acc: 71.88%\n",
      "Epoch: 37 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.770 | Train Acc: 71.48%\n",
      "\t Val. Loss: 0.727 |  Val. Acc: 78.12%\n",
      "Epoch: 38 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.767 | Train Acc: 69.66%\n",
      "\t Val. Loss: 0.789 |  Val. Acc: 68.75%\n",
      "Epoch: 39 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.772 | Train Acc: 68.82%\n",
      "\t Val. Loss: 0.797 |  Val. Acc: 68.75%\n",
      "Epoch: 40 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.750 | Train Acc: 71.48%\n",
      "\t Val. Loss: 0.783 |  Val. Acc: 65.62%\n",
      "Epoch: 41 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.745 | Train Acc: 71.09%\n",
      "\t Val. Loss: 0.684 |  Val. Acc: 75.00%\n",
      "Epoch: 42 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.737 | Train Acc: 70.83%\n",
      "\t Val. Loss: 0.716 |  Val. Acc: 71.88%\n",
      "Epoch: 43 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.735 | Train Acc: 71.94%\n",
      "\t Val. Loss: 0.744 |  Val. Acc: 68.75%\n",
      "Epoch: 44 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.738 | Train Acc: 69.40%\n",
      "\t Val. Loss: 0.767 |  Val. Acc: 71.88%\n",
      "Epoch: 45 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.722 | Train Acc: 70.57%\n",
      "\t Val. Loss: 0.809 |  Val. Acc: 62.50%\n",
      "Epoch: 46 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.699 | Train Acc: 74.22%\n",
      "\t Val. Loss: 0.727 |  Val. Acc: 65.62%\n",
      "Epoch: 47 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.694 | Train Acc: 74.67%\n",
      "\t Val. Loss: 0.746 |  Val. Acc: 65.62%\n",
      "Epoch: 48 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.692 | Train Acc: 72.07%\n",
      "\t Val. Loss: 0.764 |  Val. Acc: 65.62%\n",
      "Epoch: 49 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.685 | Train Acc: 73.05%\n",
      "\t Val. Loss: 0.777 |  Val. Acc: 62.50%\n",
      "Epoch: 50 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.679 | Train Acc: 72.85%\n",
      "\t Val. Loss: 0.862 |  Val. Acc: 71.88%\n",
      "Epoch: 51 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.672 | Train Acc: 73.24%\n",
      "\t Val. Loss: 0.694 |  Val. Acc: 75.00%\n",
      "Epoch: 52 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.675 | Train Acc: 72.59%\n",
      "\t Val. Loss: 0.705 |  Val. Acc: 68.75%\n",
      "Epoch: 53 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.652 | Train Acc: 74.87%\n",
      "\t Val. Loss: 0.721 |  Val. Acc: 68.75%\n",
      "Epoch: 54 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.638 | Train Acc: 75.20%\n",
      "\t Val. Loss: 0.670 |  Val. Acc: 75.00%\n",
      "Epoch: 55 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.634 | Train Acc: 74.48%\n",
      "\t Val. Loss: 0.718 |  Val. Acc: 68.75%\n",
      "Epoch: 56 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.633 | Train Acc: 74.87%\n",
      "\t Val. Loss: 0.666 |  Val. Acc: 78.12%\n",
      "Epoch: 57 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.618 | Train Acc: 77.21%\n",
      "\t Val. Loss: 0.627 |  Val. Acc: 75.00%\n",
      "Epoch: 58 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.608 | Train Acc: 75.00%\n",
      "\t Val. Loss: 0.571 |  Val. Acc: 84.38%\n",
      "Epoch: 59 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.626 | Train Acc: 75.33%\n",
      "\t Val. Loss: 0.765 |  Val. Acc: 71.88%\n",
      "Epoch: 60 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.620 | Train Acc: 76.17%\n",
      "\t Val. Loss: 0.641 |  Val. Acc: 81.25%\n",
      "Epoch: 61 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.570 | Train Acc: 77.93%\n",
      "\t Val. Loss: 0.698 |  Val. Acc: 71.88%\n",
      "Epoch: 62 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.583 | Train Acc: 77.15%\n",
      "\t Val. Loss: 0.764 |  Val. Acc: 75.00%\n",
      "Epoch: 63 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.575 | Train Acc: 76.43%\n",
      "\t Val. Loss: 0.672 |  Val. Acc: 68.75%\n",
      "Epoch: 64 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.568 | Train Acc: 78.78%\n",
      "\t Val. Loss: 0.624 |  Val. Acc: 75.00%\n",
      "Epoch: 65 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.553 | Train Acc: 78.71%\n",
      "\t Val. Loss: 0.660 |  Val. Acc: 71.88%\n",
      "Epoch: 66 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.552 | Train Acc: 77.60%\n",
      "\t Val. Loss: 0.559 |  Val. Acc: 71.88%\n",
      "Epoch: 67 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.556 | Train Acc: 77.80%\n",
      "\t Val. Loss: 0.609 |  Val. Acc: 71.88%\n",
      "Epoch: 68 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.545 | Train Acc: 77.15%\n",
      "\t Val. Loss: 0.609 |  Val. Acc: 71.88%\n",
      "Epoch: 69 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.532 | Train Acc: 78.39%\n",
      "\t Val. Loss: 0.634 |  Val. Acc: 65.62%\n",
      "Epoch: 70 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.524 | Train Acc: 78.91%\n",
      "\t Val. Loss: 0.623 |  Val. Acc: 68.75%\n",
      "Epoch: 71 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.506 | Train Acc: 79.30%\n",
      "\t Val. Loss: 0.635 |  Val. Acc: 59.38%\n",
      "Epoch: 72 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.494 | Train Acc: 79.56%\n",
      "\t Val. Loss: 0.659 |  Val. Acc: 71.88%\n",
      "Epoch: 73 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.480 | Train Acc: 79.17%\n",
      "\t Val. Loss: 0.678 |  Val. Acc: 71.88%\n",
      "Epoch: 74 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.478 | Train Acc: 81.64%\n",
      "\t Val. Loss: 0.591 |  Val. Acc: 68.75%\n",
      "Epoch: 75 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.482 | Train Acc: 80.34%\n",
      "\t Val. Loss: 0.620 |  Val. Acc: 78.12%\n",
      "Epoch: 76 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.474 | Train Acc: 81.25%\n",
      "\t Val. Loss: 0.551 |  Val. Acc: 71.88%\n",
      "Epoch: 77 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.458 | Train Acc: 81.90%\n",
      "\t Val. Loss: 0.657 |  Val. Acc: 71.88%\n",
      "Epoch: 78 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.477 | Train Acc: 81.32%\n",
      "\t Val. Loss: 0.484 |  Val. Acc: 78.12%\n",
      "Epoch: 79 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.438 | Train Acc: 82.03%\n",
      "\t Val. Loss: 0.551 |  Val. Acc: 78.12%\n",
      "Epoch: 80 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.446 | Train Acc: 81.18%\n",
      "\t Val. Loss: 0.573 |  Val. Acc: 75.00%\n",
      "Epoch: 81 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.438 | Train Acc: 81.64%\n",
      "\t Val. Loss: 0.553 |  Val. Acc: 75.00%\n",
      "Epoch: 82 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.432 | Train Acc: 81.45%\n",
      "\t Val. Loss: 0.474 |  Val. Acc: 84.38%\n",
      "Epoch: 83 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.430 | Train Acc: 82.94%\n",
      "\t Val. Loss: 0.505 |  Val. Acc: 81.25%\n",
      "Epoch: 84 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.418 | Train Acc: 83.79%\n",
      "\t Val. Loss: 0.587 |  Val. Acc: 71.88%\n",
      "Epoch: 85 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.421 | Train Acc: 81.51%\n",
      "\t Val. Loss: 0.632 |  Val. Acc: 84.38%\n",
      "Epoch: 86 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.403 | Train Acc: 84.18%\n",
      "\t Val. Loss: 0.420 |  Val. Acc: 78.12%\n",
      "Epoch: 87 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.411 | Train Acc: 82.10%\n",
      "\t Val. Loss: 0.651 |  Val. Acc: 71.88%\n",
      "Epoch: 88 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.403 | Train Acc: 83.46%\n",
      "\t Val. Loss: 0.610 |  Val. Acc: 75.00%\n",
      "Epoch: 89 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.400 | Train Acc: 84.57%\n",
      "\t Val. Loss: 0.480 |  Val. Acc: 78.12%\n",
      "Epoch: 90 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.381 | Train Acc: 83.98%\n",
      "\t Val. Loss: 0.458 |  Val. Acc: 75.00%\n",
      "Epoch: 91 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.372 | Train Acc: 85.16%\n",
      "\t Val. Loss: 0.533 |  Val. Acc: 71.88%\n",
      "Epoch: 92 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.369 | Train Acc: 85.42%\n",
      "\t Val. Loss: 0.487 |  Val. Acc: 75.00%\n",
      "Epoch: 93 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.346 | Train Acc: 85.94%\n",
      "\t Val. Loss: 0.564 |  Val. Acc: 81.25%\n",
      "Epoch: 94 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.376 | Train Acc: 85.94%\n",
      "\t Val. Loss: 0.498 |  Val. Acc: 75.00%\n",
      "Epoch: 95 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.335 | Train Acc: 85.94%\n",
      "\t Val. Loss: 0.352 |  Val. Acc: 84.38%\n",
      "Epoch: 96 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.354 | Train Acc: 84.18%\n",
      "\t Val. Loss: 0.359 |  Val. Acc: 87.50%\n",
      "Epoch: 97 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.363 | Train Acc: 84.38%\n",
      "\t Val. Loss: 0.573 |  Val. Acc: 81.25%\n",
      "Epoch: 98 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.352 | Train Acc: 85.94%\n",
      "\t Val. Loss: 0.505 |  Val. Acc: 68.75%\n",
      "Epoch: 99 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.344 | Train Acc: 85.16%\n",
      "\t Val. Loss: 0.526 |  Val. Acc: 81.25%\n",
      "Epoch: 100 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.325 | Train Acc: 87.70%\n",
      "\t Val. Loss: 0.384 |  Val. Acc: 84.38%\n",
      "Epoch: 101 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.325 | Train Acc: 87.30%\n",
      "\t Val. Loss: 0.519 |  Val. Acc: 81.25%\n",
      "Epoch: 102 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.305 | Train Acc: 87.96%\n",
      "\t Val. Loss: 0.562 |  Val. Acc: 75.00%\n",
      "Epoch: 103 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.331 | Train Acc: 86.33%\n",
      "\t Val. Loss: 0.533 |  Val. Acc: 84.38%\n",
      "Epoch: 104 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.290 | Train Acc: 89.06%\n",
      "\t Val. Loss: 0.750 |  Val. Acc: 78.12%\n",
      "Epoch: 105 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.295 | Train Acc: 89.06%\n",
      "\t Val. Loss: 0.624 |  Val. Acc: 75.00%\n",
      "Epoch: 106 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.300 | Train Acc: 89.13%\n",
      "\t Val. Loss: 0.403 |  Val. Acc: 87.50%\n",
      "Epoch: 107 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.291 | Train Acc: 88.87%\n",
      "\t Val. Loss: 0.720 |  Val. Acc: 71.88%\n",
      "Epoch: 108 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.300 | Train Acc: 87.76%\n",
      "\t Val. Loss: 0.769 |  Val. Acc: 75.00%\n",
      "Epoch: 109 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.316 | Train Acc: 85.81%\n",
      "\t Val. Loss: 0.515 |  Val. Acc: 84.38%\n",
      "Epoch: 110 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.275 | Train Acc: 88.54%\n",
      "\t Val. Loss: 0.438 |  Val. Acc: 87.50%\n",
      "Epoch: 111 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.274 | Train Acc: 89.71%\n",
      "\t Val. Loss: 0.428 |  Val. Acc: 81.25%\n",
      "Epoch: 112 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.270 | Train Acc: 88.09%\n",
      "\t Val. Loss: 0.519 |  Val. Acc: 84.38%\n",
      "Epoch: 113 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.272 | Train Acc: 89.13%\n",
      "\t Val. Loss: 0.395 |  Val. Acc: 87.50%\n",
      "Epoch: 114 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.291 | Train Acc: 86.98%\n",
      "\t Val. Loss: 0.623 |  Val. Acc: 68.75%\n",
      "Epoch: 115 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.264 | Train Acc: 89.06%\n",
      "\t Val. Loss: 0.466 |  Val. Acc: 87.50%\n",
      "Epoch: 116 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.270 | Train Acc: 89.32%\n",
      "\t Val. Loss: 0.378 |  Val. Acc: 87.50%\n",
      "Epoch: 117 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.297 | Train Acc: 89.84%\n",
      "\t Val. Loss: 0.387 |  Val. Acc: 84.38%\n",
      "Epoch: 118 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.242 | Train Acc: 91.02%\n",
      "\t Val. Loss: 0.368 |  Val. Acc: 87.50%\n",
      "Epoch: 119 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.259 | Train Acc: 89.06%\n",
      "\t Val. Loss: 0.384 |  Val. Acc: 87.50%\n",
      "Epoch: 120 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.236 | Train Acc: 91.21%\n",
      "\t Val. Loss: 0.769 |  Val. Acc: 78.12%\n",
      "Epoch: 121 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.236 | Train Acc: 90.43%\n",
      "\t Val. Loss: 0.450 |  Val. Acc: 84.38%\n",
      "Epoch: 122 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.228 | Train Acc: 91.86%\n",
      "\t Val. Loss: 0.586 |  Val. Acc: 84.38%\n",
      "Epoch: 123 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.232 | Train Acc: 90.30%\n",
      "\t Val. Loss: 0.550 |  Val. Acc: 81.25%\n",
      "Epoch: 124 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.209 | Train Acc: 92.19%\n",
      "\t Val. Loss: 0.814 |  Val. Acc: 71.88%\n",
      "Epoch: 125 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.227 | Train Acc: 91.21%\n",
      "\t Val. Loss: 0.513 |  Val. Acc: 84.38%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 125\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut-model.pt')\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:56.746101Z",
     "iopub.status.busy": "2020-08-12T21:06:56.745716Z",
     "iopub.status.idle": "2020-08-12T21:06:56.765547Z",
     "shell.execute_reply": "2020-08-12T21:06:56.764964Z",
     "shell.execute_reply.started": "2020-08-12T21:06:56.746074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.459 | Test Acc: 82.50%\n"
     ]
    }
   ],
   "source": [
    "test_transforms = transforms.Compose([\n",
    "                            transforms.Grayscale(num_output_channels=1),\n",
    "                            transforms.Resize(10),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean = [mean], std = [std])\n",
    "                                      ])\n",
    "\n",
    "test_iterator = data.DataLoader(test_data, \n",
    "                                batch_size = BATCH_SIZE)\n",
    "model.load_state_dict(torch.load('tut-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion, device)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:56.766923Z",
     "iopub.status.busy": "2020-08-12T21:06:56.766558Z",
     "iopub.status.idle": "2020-08-12T21:06:56.770539Z",
     "shell.execute_reply": "2020-08-12T21:06:56.769965Z",
     "shell.execute_reply.started": "2020-08-12T21:06:56.766896Z"
    }
   },
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(8,1,10,10, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:56.772045Z",
     "iopub.status.busy": "2020-08-12T21:06:56.771538Z",
     "iopub.status.idle": "2020-08-12T21:06:56.807426Z",
     "shell.execute_reply": "2020-08-12T21:06:56.806802Z",
     "shell.execute_reply.started": "2020-08-12T21:06:56.772019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input.1 : Float(8, 1, 10, 10),\n",
      "      %conv1.weight : Float(3, 1, 3, 3),\n",
      "      %conv1.bias : Float(3),\n",
      "      %conv2.weight : Float(6, 3, 3, 3),\n",
      "      %conv2.bias : Float(6),\n",
      "      %fc_1.weight : Float(72, 216),\n",
      "      %fc_1.bias : Float(72),\n",
      "      %fc_2.weight : Float(24, 72),\n",
      "      %fc_2.bias : Float(24),\n",
      "      %fc_3.weight : Float(6, 24),\n",
      "      %fc_3.bias : Float(6)):\n",
      "  %11 : Float(8, 3, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%input.1, %conv1.weight, %conv1.bias), scope: LeNet/Conv2d[conv1] # /opt/tljh/user/lib/python3.7/site-packages/torch/nn/modules/conv.py:340:0\n",
      "  %12 : Float(8, 3, 8, 8) = onnx::Relu(%11), scope: LeNet # /opt/tljh/user/lib/python3.7/site-packages/torch/nn/functional.py:913:0\n",
      "  %13 : Float(8, 6, 6, 6) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%12, %conv2.weight, %conv2.bias), scope: LeNet/Conv2d[conv2] # /opt/tljh/user/lib/python3.7/site-packages/torch/nn/modules/conv.py:340:0\n",
      "  %14 : Float(8, 6, 6, 6) = onnx::Relu(%13), scope: LeNet # /opt/tljh/user/lib/python3.7/site-packages/torch/nn/functional.py:913:0\n",
      "  %15 : Long() = onnx::Constant[value={0}](), scope: LeNet\n",
      "  %16 : Tensor = onnx::Shape(%14), scope: LeNet\n",
      "  %17 : Long() = onnx::Gather[axis=0](%16, %15), scope: LeNet # <ipython-input-10-ebaa05aff6fc>:39:0\n",
      "  %18 : Long() = onnx::Constant[value={-1}](), scope: LeNet\n",
      "  %19 : Tensor = onnx::Unsqueeze[axes=[0]](%17)\n",
      "  %20 : Tensor = onnx::Unsqueeze[axes=[0]](%18)\n",
      "  %21 : Tensor = onnx::Concat[axis=0](%19, %20)\n",
      "  %22 : Float(8, 216) = onnx::Reshape(%14, %21), scope: LeNet # <ipython-input-10-ebaa05aff6fc>:39:0\n",
      "  %23 : Float(8, 72) = onnx::Gemm[alpha=1, beta=1, transB=1](%22, %fc_1.weight, %fc_1.bias), scope: LeNet/Linear[fc_1] # /opt/tljh/user/lib/python3.7/site-packages/torch/nn/functional.py:1369:0\n",
      "  %24 : Float(8, 72) = onnx::Relu(%23), scope: LeNet # /opt/tljh/user/lib/python3.7/site-packages/torch/nn/functional.py:913:0\n",
      "  %25 : Float(8, 24) = onnx::Gemm[alpha=1, beta=1, transB=1](%24, %fc_2.weight, %fc_2.bias), scope: LeNet/Linear[fc_2] # /opt/tljh/user/lib/python3.7/site-packages/torch/nn/functional.py:1369:0\n",
      "  %26 : Float(8, 24) = onnx::Relu(%25), scope: LeNet # /opt/tljh/user/lib/python3.7/site-packages/torch/nn/functional.py:913:0\n",
      "  %27 : Float(8, 6) = onnx::Gemm[alpha=1, beta=1, transB=1](%26, %fc_3.weight, %fc_3.bias), scope: LeNet/Linear[fc_3] # /opt/tljh/user/lib/python3.7/site-packages/torch/nn/functional.py:1369:0\n",
      "  return (%27, %22)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "torch.onnx.export(model, dummy_input, \"model_file.onnx\",verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:56.810212Z",
     "iopub.status.busy": "2020-08-12T21:06:56.809809Z",
     "iopub.status.idle": "2020-08-12T21:06:56.950779Z",
     "shell.execute_reply": "2020-08-12T21:06:56.950141Z",
     "shell.execute_reply.started": "2020-08-12T21:06:56.810185Z"
    }
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "model=onnx.load_model('model_file.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:56.952274Z",
     "iopub.status.busy": "2020-08-12T21:06:56.951910Z",
     "iopub.status.idle": "2020-08-12T21:06:56.956581Z",
     "shell.execute_reply": "2020-08-12T21:06:56.955426Z",
     "shell.execute_reply.started": "2020-08-12T21:06:56.952236Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"./model_file_deepC\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-12T21:06:56.958478Z",
     "iopub.status.busy": "2020-08-12T21:06:56.958058Z",
     "iopub.status.idle": "2020-08-12T21:06:56.962091Z",
     "shell.execute_reply": "2020-08-12T21:06:56.961342Z",
     "shell.execute_reply.started": "2020-08-12T21:06:56.958441Z"
    }
   },
   "outputs": [],
   "source": [
    "!compile-onnx model_file.onnx ./model_file_deepC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
